# ØMQ - The Guide
# РУКОВОДСТВО

Pieter Hintjens главный исполнительный директор iMatix
Пожалуйста используйте трекер задач для всех комментариев и ошибок. Данная версия по последней стабильной версии ZeroMQ (3.2).
Если вы используете старую версию ZeroMQ то некоторые данные могуть различаться.
Руководство предоставляет примера на Си, но так же PHP, Python, Lua, and Haxe. Так же мы перевели большинство примеров на C++, C#, CL, Delphi, Erlang, F#, Felix, Haskell, Java, Objective-C, Ruby, Ada, Basic, Clojure, Go, Haxe, Node.js, ooc, Perl, and Scala.


## Предисловие

### Кратко о ZeroMQ

ZeroMQ (так же известная как  ØMQ, 0MQ, или zmq) является встраиваемой сетевой библиотекой, но используется как фреймворк для паралеллизма. Она предоставляетс сокеты для передачи атомарных сообщений поверх различных транспортных уровней, таких как Межпроцеccное взаимодействие(IPC), tcp и широковещательное (multicast). Вы можете подключить сокеты М-М(многие ко многим) используя паттерны такое как  fan-out(?Не известно?), pub-sub(издатель-подписчик), task distribution(распределение задач), и request-reply(запрос-ответ). Все это предоставляет достаточные скорости для кластеризации. Асинхронная модель ввода/вывода предоставляет гибкость для построения многоядерных приложений(Многопоточных), построенных как многопоточные задачи. Поддерживает множестко языков программирования и запускается на большинстве популярных ос. ZeroMQ от iMatix распространяется под лицензией LGPLv3 с открытым исходным кодом.

### Как это началось

Мы взяли обычные tcp сокеты, добавили в них смесь радиоактивных изотопов похищеных из секретного советского проекта атомных исследований, бомбанули по нему космическими лучами 1950-х годов и отдали его в руки обдолбанного автора комиксов с фетишем обтягивающего трико. Да сокеты ZeroMQ это супергерои которые призваны спасти сетевой мир.

### Дзен ZeroMQ

Ноль в наимерновании ZeroMQ означает компромис. С одной стороны такое странное название снижает позиции в google и twitter. С другой стороны это раздражает некоторых датчан которые пишун нам такие вещи как "ØMG røtfl", и «Ø не забавный нулевой!» и «Rødgrød med fløde!», что, по-видимому, является оскорблением, которое означает «пусть ваши соседи станут прямыми потомками Гренделя!» Вроде бы справедливый обмен.

На самом деле ной в наимерновании ZeroMQ означает "нулевой брокер" и (как можно быстрее) "нулевая задержка". С того времени это захватило все больше вещей: Нулевое администрирование, нулевая стоимость, ноль отходов. В более общем плане «нуль» относится к культуре минимализма, концепции которой придерживатеся проект. Мы подкрутили мощность, удаляя сложность, а не функционал.

### Для кого эта книга

Эта книга написана для профессиональных программистов кто хочет узнать как создавать огромные распределенные системы доминирующие в нише компьютеров. Надеемся вы знаете и умеете читать код на СИ, так как большинство примеров в книге приведены на СИ, хотя ZeroMQ может быть премен в множестве языков. Предполагается что вам нужен лучший результат за меньшие деньги, иначе вы разочаруетесь копрописами предоставленными ZeroMQ. Помимо базовых вещей мы попытаемсяпредставить все концепции сетевых и распределенных вычислений, они вам понадобятся при работе с ZeroMQ.

### Благодарности.

Спасибо Andy Oram за возможность выхода книги O'Reilly и редактирования этого текста.

Спасибо Bill Desmarais, Brian Dorsey, Daniel Lin, Eric Desgranges, Gonzalo Diethelm, Guido Goldstein, Hunter Ford, Kamil Shakirov, Martin Sustrik, Mike Castleman, Naveen Chawla, Nicola Peduzzi, Oliver Smith, Olivier Chamoux, Peter Alexander, Pierre Rouleau, Randy Dryburgh, John Unwin, Alex Thomas, Mihail Minkov, Jeremy Avnet, Michael Compton, Kamil Kisiel, Mark Kharitonov, Guillaume Aubert, Ian Barber, Mike Sheridan, Faruk Akgul, Oleg Sidorov, Lev Givon, Allister MacLeod, Alexander D'Archangel, Andreas Hoelzlwimmer, Han Holl, Robert G. Jakabosky, Felipe Cruz, Marcus McCurdy, Mikhail Kulemin, Dr. Gergő Érdi, Pavel Zhukov, Alexander Else, Giovanni Ruggiero, Rick "Technoweenie", Daniel Lundin, Dave Hoover, Simon Jefford, Benjamin Peterson, Justin Case, Devon Weller, Richard Smith, Alexander Morland, Wadim Grasza, Michael Jakl, Uwe Dauernheim, Sebastian Nowicki, Simone Deponti, Aaron Raddon, Dan Colish, Markus Schirp, Benoit Larroque, Jonathan Palardy, Isaiah Peng, Arkadiusz Orzechowski, Umut Aydin, Matthew Horsfall, Jeremy W. Sherman, Eric Pugh, Tyler Sellon, John E. Vincent, Pavel Mitin, Min RK, Igor Wiedler, Olof Åkesson, Patrick Lucas, Heow Goodman, Senthil Palanisami, John Gallagher, Tomas Roos, Stephen McQuay, Erik Allik, Arnaud Cogoluègnes, Rob Gagnon, Dan Williams, Edward Smith, James Tucker, Kristian Kristensen, Vadim Shalts, Martin Trojer, Tom van Leeuwen, Hiten Pandya, Harm Aarts, Marc Harter, Iskren Ivov Chernev, Jay Han, Sonia Hamilton, Nathan Stocks, Naveen Palli, и Zed Shaw за их участие в этой работе.



## ГЛАВА 1 - ОСНОВЫ

### Исправление мира

Как можно описать ZeroMQ? Некоторые из нас начинают перечислять все плюшки которые предоставляет зера. По сути это сокеты на стероидах. Это как почтовые ящики с маршрутизацией. Это быстро! Другие попытаются поделиться своим моментом просветления, что бум-бах и их парадигма сдвинулась когда все это стало очевидным. Все становится проще. Сложность уходит. Разум просветляется. Кто-то попытается объястить на примере сравнения. Это проще, легковеснее, но все еще нам знакомо. Хочу напомнить для чего мы вообще создали Зеру, потому что есть люди которым это нужно.

Программирование это наука завуалированная под искусство, так как большинство из нас не понимает программирования на физическом уровне и вообще редко когда изучает этот аспект. Физика программного обеспечения это не алгоритмы, структуры данных, языки и абстракции. Это просто инструменты которе мы делаем, используем, а затем выбрасываем. Реальная физика ПО это физика человека - в частности наши физические ограничения, когда дело касается сложности ПО, а так же наше решение работать в команде чтобы разделить сложную реальзацию по кучоскам. Это наука программирования: создание конструктивных блоков, легких в понимании и использовании людьми, тогда и только тогда люди могут решать громадные проблемы.

Мы живем в связанном мире, и современное программное обеспечение должно подстраиваться под этот мир. Создание блоков на завтра очень громоздкое решение, связное со множеством мультипоточности. Это больше не соответствует заповеди "чистого кода". Код должен взаимодействовать с кодом. Код должен быть говорящим, дружелюбным и легко подключаемым.
Код должен стартовать как человеческий мозг, триллионами нейронных нитей с сообщениями в каждой из них, с громадной параллейльной сетью не имебщей центра управления, не имеющей точки отказа, но способный решать черезвычайно сложные задачи. И это не случайно, что будущее кода выглядит как человеческий мозг, поскольку конечные точки каждой сети на некотором уровне являются человеческим мозгом.

Поработайте с потоками, протоколами, или сетями и вы поймете что это практически невозможно. Это мечта. Даже подключение всего нескольких программ через несколько сокетов довольно неприятное занятие, когда вы прочувствуете это на деле. Триллионы? Цена за такое даже не вообразима. Связать компьютеры настолько сложно что это порадило многомиллиаржные бизнесы по созданию программного обеспечения под все это.

По-этому мы живем в мире где железо намного опережает наши способности его обуздать. Во время кризиса 80х готов, когда даже такие тимлиды как Фред Брукс не верили в существование "серебряной пули" способной проднять планку совершенства хотя бы на единицу в производительности, надежности и простоте.

Брукс упустил из виду открытое ПО, которое справится с этим кризисом, подтолкнув нас делиться опытом гораздо эффективнее. Сегодня нас настиг другой кризис ПО, но мы про это промолчим. Только большие, богатые фирмы могут позволить себе разработку связных приложений. Существует облако, но оно закрытое. Наши персональные данные перекачевывают в облака, к которым у нас нет доступа и которым мы не конкуренты. Кто владеет нашими соц-сетями. Это похоже на на революцию менфреймов в обратном направлении.

Мы оставим политическую философию для другой книги. Дело в том что хоть интернет и предполагает большой потенциал массового связывания кода, реальность такова, что для большинства такая задача непреодалима, и большие интересные проблемы (в здравоохранении, образовании, экономике, транспорта и тд) остаются не решенными, так как нет возможноти это все связать, нет возможности продумать и работать совместно над этими проблемами.

Было множество попыток решения проблем общения между кодом. Существуют тысячи спецификаций IETF, каждая из которых разрешает часть головоломки. Для разработчиков приложений HTTP - это пожалуй одно из решений достаточно простое для работы, но пораждающую проблему куда хуже, поощряя разработчиков и архитекторов думать большими сервисами и тонкими тупыми клиентами.

Сегодня все еще соединяют приложения посрежством чистых UDP и TCP, закрытых протоколов, http и веб-сокетов. Это пораждает головную боль для разработчиков, медлительность, сложность в масштабировании, в так же централизацию. Распределенные архитектуры P2P в основном предназначены для баловства, а не для работы. Сколько приложений использует Skype или Bittorrent для обмена данными?

Это возвращает нас к изучению программирования. Чтобы исправить мир нам нужно две вещи. Первая, решить проблему того чтобы любой код мог взаимодействовать с любым кодом. Вторая, запаковать это в такой инструмен, который помогал бы легко конструировать блоки кода, которые легко понять человеку и легко использовать.

Звучить до смешного просто. Может так оно и есть. Вот и все.


## НЕОБХОДИМЫЕ ВВОДНЫЕ.

Договоримся, что вы используете хотя бы версию 3.2 Зеры. Договоримся что в примерах мы используем ос линукс или подобную. Предположим вы умеете читать код на Си, чтобы более или менее понимать примеры. Договоримся что когда мы пишем обобщенные константы PUSH или SUBSCRIBE имеются ввиду ZMQ_PUSH или ZMQ_SUBSCRIBE, что зависит от языка программирования и вы сами их подставите к себе.

### ПРИМЕРЫ

Примеры находятся в публичном git репозитории. Простейшим путем будет просто склонировать их к себе в директори.

git clone --depth=1 git://github.com/imatix/zguide.git

Далее в своей директории вы найдете примеры для различных языков программирования. Если все же ваш язык отсутсвует, то мы поощряем предоставление примеров для него. Таким образом зародились эти примеры, спасибо всем за приложенные к этому усилия. Все примеры распространяются по лицензии MIT/X11.



### ПРОСИТЕ И ДАНО ВАМ БУДЕТ.

Давайте же уже перейдем к коду. Разумеется мы начнем с Hello World. Для начала создадим клиента и сервер. Клиент отправляет "HELLO" на сервер и получает в ответ "WORLD"(рис 2).
В примере болок кода сервера на языке СИ. Он отрывает сокет Зеры на порту 5555, читает из него запросы и отчечает "WORLD" на каждый из них.

Пара сокетоа типа REQ-REP(запрос-ответ) являются последовательно-зависимой. Клиент в цикле сначала отправляет запрос zmq_send() и только после этого ждет ответ then zmq_recv(). Использование другой последовательности (к примеру отправка подряд двух сообщений) приведет к тому что функция вернет -1. Аналогичным образом сервисы сначала слущают запрос zmq_recv() и только после этого отправляют на него ответ zmq_send().

Зера использует Си и это так же основной язык для написания примеров. Если вы читаете это на сайте то снизу будут ссылки для примеров переведенных на разные языки. Теперь давайте сравним аналогичный серве на С++:
Example 2. Hello World server (hwserver.cpp)

Как вы можете убедиться API для языков СИ и С++ аналогичны. На языке таком как php, мы можем скрыть большинство реализации и сделать код еще более легким и читаемым:
Example 3. Hello World server (hwserver.php)

А вот код клиента:
Example 4. Hello World client (hwclient.c)

Теперь это выглядит слишком просто чтобы быть правдой, но не забывайте что сокеты Зеры имеют суперсилы. Вы можете навешать на этот сервер тысячи клиентов и он проболжит работать быстро и припеваючи работать. Для прикола запустите сначала клиента и только потом сервер. Смотри это все еще работает и не падает, задумайтесь на секунду почему так происходит.

Давайте кратко посмотрим как эти две программы действительно работают. Они создают контекст Зеры и сокеты для работы. Не запаривайтесь о значении этих терминов. Скоро вы все поймете. Сервер навешивает свой сокет REP(ответ) на порт 5555. Сервер в цикле ожидет запроса, и отвечает на каждый. Клиент отправляет запрос и ожидает на него ответа. Если вы перезапустите сервер, клиент сам не поднимется. Поднятие после сбоят так просто не пройдет. Создание отказоустойчивых соединений типа запрос-ответ(request-reply) довольно сложный процесс и мы до него еще дойдем когда будем рассматривать "надежные паттерны ответ-запрос"("Reliable Request-Reply Patterns"). 

Многое произходит за кадром, на для нас программистов важно чтобы код был красивым, аккуратным и не падал под нагрузками. Это паттерн запрос-ответ(request-reply), возможно простейший способ использования Зеры. Это отражение RPC и классической клиент-серверной модели.

### СНОСОЧКА ПРО СТРОКИ(A Minor Note on Strings)

Зера ничего не знает о том что за данные вы отправляете, за исключением размера в байтах. Это означает что вся ответственность за форматирование и безопасность целиком на вас. Для отправки объектов и структур данных используйте специализированные библиотеки такие как "Протокол Буфферов". Но так же не забывайте позаботиться и о простых строковых данных.
В СИ и некоторых других языках строки оканчиваются нулевым байтом. Мы должны отправить строку типа "HELLO" вместе с закрывающим нулевым байтом

zmq_send (requester, "Hello", 6, 0);

Однако если вы используете другой язык, то можно не заботиться о нулевом байте. К примеру отпрака той же строки на языке Python, выглядит вот так:

socket.send ("Hello")

Тогда то что будет отправлено это длинна(один байт определяющий длинну) и содержимое строки в виде отдельных ее символов(рис 3).
И если вы читаете это на стороне кода СИ вы получите нечто выглядещее как строка (если повезет все пять байт выстроятся как надо), но ею не являющейся. Когда ваши клиент серверные приложения не имеют согласованного формата строк, вам придется выуживать данные. 

Когда вы получаете данные на строне языка СИ, нельзя безоговорочно доверять тому что строка будет корректно завершена mull байтом. Каждый раз при приеме сообщения вам нужно выделить память под это строку с учетом закрывающего байта, скопировать туда строку и самостоятельно завершить строку null байтом. В таком случае давайте установим правило - Строки Зеры зависимы от длинны и не имеют закрывающего null байта. В лучшем случае Зера обработает кусок сообщения как показано на рисунке выше - с учетом байта длинны и последующих за ним байт.

Вот что необходимо сделать на стороне кода на СИ чтобы получить строку и корректно ее обработать для превращения в корректную строку.

// Receive 0MQ string from socket and convert into C string
// Chops string at 255 chars, if it's longer
static char *
s_recv (void *socket) {
 char buffer [256];
 int size = zmq_recv (socket, buffer, 255, 0);
 if (size == -1)
 return NULL;
 if (size > 255)
 size = 255;
 buffer [size] = 0;
 return strdup (buffer);
}

Этот код можно превратить во вспомогательную функцию и подключать ее в заголовках. Собственно что и сделано в  zhelpers.h. Это поможет сделать разработку на Зере красивее и приятнее на языке СИ. Код слишком длинный чтобы его тут выплевывать, так что истинные фанатики СИ прочтут его на досуге(https://github.com/booksbyus/zguide/blob/master/examples/C/zhelpers.h).

### ВЕРСИОНИРОВАНИЕ.(Version Reporting)

Зера существует в нескольких версиях и если вы сталкнулись с какой то проблемой, то скорее всего это уже исправлено в следующей версии. Так что полезным трюком будет знать какую версию либы ви используете. Вот маленькая программа позволяющая определить текущую версию. 
Example 5. ØMQ version reporting (version.c)

### ПОЛУЧЕНИЕ СООБЩЕНИЯ.(Getting the Message Out)

Второй классический паттерн это односторонняя пепесылка, когда сервер отправляет обновления набору клиентов. Давайте посмотрим на пример в котором сервер отправляет обновления почтовых индексов, температуры и влажности. Будем генерировать произвольные значения, чтобы съэмулировать поведения погоды.

Пример сервера. Используем порт 5556 для приложения для клиента.

Example 6. Weather update server (wuserver.c)

Это нескончаемый широковещательный поток(рис.4)

Пример клиента который слушает все оповещения об изменениях и парсит их. По дефолту почтовый индекс будет для Нью Йорка.

Example 7. Weather update client (wuclient.c)

Обратите внимание что когда вы используете SUB сокет вы ДОЛЖНЫ установить подписчика используя функцию zmq_setsockopt() и тем самым подписаться как в примере. Если вы ни на что не подписались вы ничего не получите. Это частая ошибка для новичков. Подписчик может одновременно подписаться на множество каналов. И если обновление соответсвует любой из этих подписок то подписчик получит это сообщение. Так же есть возможность отписаться от любой подписки. Подписка чаще всего задается в виде человекочитаемой стоки, но это не жесткое ограничение. Дополнительно можно посмотреть в описании функции zmq_setsockopt().

Пара сокетов издатель-подписчик(PUB-SUB) является асинхронной. Клиент вызывает в цикле(или единажды если нужно) zmq_recv(). При попытке отправить сообщение по SUB сокету вызовет ошибку. Аналогично сервис вызывает zmq_send() когда это нужно, но не может вызвать zmq_recv() на сокете подписчика(PUB).

Теоретически Зере плевать кто слушает, а кто подключается к сокету. Однако на практике есть незадокументированные отличия, о которых мы поговорим позже. Сейчас просто слушаем PUB и подключаемся к SUB.

Еще одна важная вещь с сокетами типа подписчик-издатель которую нужно знать и учитывать. Вы не знаете когда подписчик начнет получить сообщения. Даже если вы сначала запустите подписчика и только после этого, выдержав паузу, запустите издателя, ПОДПИСЧИК ВСЕГДА ПРОПУСТИТ ПЕРВОЕ СООБЩЕНИЕ. Это случается потому что пока подписчик подключается(обычно это делается быстро, но не моментально), издатель уже может отправть сообщение. Поскольку множество людей натыкаются на этот казус, давайте остановимся на нем подробнее. Запомните что Зера выполняте асинхронное чтение и отправку в фоновом режиме. Предположим у нас есть два узла которые выполняются в следующем порядке.

* Подписчик подключается к конечной точке, получает сообщения и считает сколько он получил сообщений.
* издатель вешается на конечную точку и немедленно отправляет 1000 сообщений.

В такм случае подписчик скорее всего ничего не получит. Вы в замешательсве, проверяете что правильно указали параметры подключения, пробуете снова и опять ничего не получили. Создание TCP соединения требует подтверждения связи между конечными узлами, что требует какое то время, которое зависит от вашей сети  и количества хопов между конечными точками. За это время Зера уже отправит кучу сообщений. К примеру для установки канала требуется 5мс и этот же канал способен обрабатывать миллион сообщений в секунду. Когда подписчику требуется целых 5мс на установку соединения, издателю потребуется всего 1мс на отправку всей тысячи сообщений.

В глеве "Паттерны по сокетам" мы расскажем как синхронизировать издателя и подписчика таким образом чтобы сообщения не отправлялись пока не будет все подписчики не законектятся и будут готовы получать сообщения. Существует простой и тупейший способ заставить издателя подождать - поставить ему задержку. Не стоит так делать, то тупейший, не красивый и медленный способ. Подождите до галавы "Паттерны по сокетам" и вы все узнаете.

Существует еще один способ. Принять решение что наш поток данных бесконечный и подписчику плевать на то что приходило до его подключения. Как к примеру в нашем примере с погодными данными.

Клиент подписывается на рассылку почтовых индексов и собирает тысячу обновлений для почтовых индексов. Сервис может нагененировать 10 миллионов сообщений. Вы можете запустить клиента, потом сервис, и клиент продолжить работать. Вы можете перезапускать сервис когда вам вздумается и клиент продолжит работать. Когда подписчик соберет 1000 сообщений, он их обработает, выведет и завершится.

Некоторые аспекты по паттерну подписчик-издатель(pub-sub):

* Подписчик может подписываться на множество издателей единовременно. Данные будут приходить и чередоваться(справедливая очередь), таким образом что один издатель не будет заглушать другого.

* Если у издателя не будет подключенных подписчиков, он просто будет отбрасывать все сообщения.

* Если вы используете tcp соединение и подписчик тормозит то сообщения будут накапливаться в очереди у издателя. Как защитить издателей от переполнения такого рода, путем установки ограничения, рассмотрим позже.

* Начиная с Зеры версии 3 и выше, если вы используете протоколы tcp:// или ipc:// фильтрация происходит на стороне издателя. При использовании протокола epgm:// фильтрация происходит на стороне подписчика. В версиях со второй по третью вся фильтрация происходит на стороне подписчика.

Ниже показано сколько времени занимает получение и фильтрация 10 миллионов сообщений, на моем лэптопе с процессором intel i5 поколения 2011 года. Прилично но ничего особенного.

$ time wuclient
Collecting updates from weather server...
Average temperature for zipcode '10001 ' was 28F
real 0m4.470s
user 0m0.000s
sys 0m0.008s

### РАЗДЕЛЯЙ И ВЛАСТВУЙ (Divide and Conquer)

В качестве последнего примера (вы наверняка уже устали от кода и хотели бы вернуться к философствованию и обсуждению абстрактных норм), давайте произведем немного суперкомпьютеров. Наше суперкомпьютерное приожение является довольно типичной моделью параллельной обработки.

У нас есть: 
	* Вентилятор который создает задачи которые можно выполнять параллельно
	* Набор воркеров которые могут обрабатывать задачи.
	* Сток(имеется ввиду место куда попадают все данные), способный собираеть воедино данные от воркеров.

В действительности воркеры запускаются в быстродействующих контейнерах, может даже на графических процессорах для сложных расчетов. Вентилятор генерирует 100 задач, каждое из которых говорит воркеру спать определенное количество милисекунд.

Example 8. Parallel task ventilator (taskvent.c)

А вот пример воркера. Он получет сообщение, спит определенно количество секунд, после чего сообщяет что он закончил.

Example 9. Parallel task worker (taskwork.c)

А вот наше приложение для сбора результатов. Оно собирает данные от 100 задач и срачитывает как долго они выполнялись. Так мы сможе убедиться что задачи выполнялись параллельно, если воркеров было несколько.

Example 10. Parallel task sink (tasksink.c)

Среднее время выполнения 5 сек. Когда мы запустим 1,2 или 4 воркера мы получим результаты схожие с этими:

1 воркер:  Общее время выполнения 5034 мс
2 воркера: Общее время выполнения 2421 мс
4 воркера: Общее время выполнения 1018 мс

Давайте глубже взглянем на код.

* Воркеры читают данные из вентилятора и отправляют их в сток. Это означает что вы можете произвольно добавлять воркеров. Если бы конечные точки задавались на воркерах вам прошлось бы (1). Использовать больше конечных точек и (2) Постоянно перезапускать вентилятор и сток, как только вы добавили воркера. По этому мы решили что вентилятор и раковина будут статичными, а воркеры динамичными.

* Мы должны синхронизировать начало запуска со всеми подключившимися воркерами. Это жовольно распространенная проблема встречающаяся в Зере и не существует волшебной таблетки. Метод zmq_connect занимает определенное время. По этому первый из воркеров который подключился, получит всю пачку задач пока все остальные подключаются. Если вы не синхронизируете запуск всей пачки сообщений, система не будет работать параллельно. Можете попробовать и убрать ожидание в вентиляторе.

* PUSH сокет вентилятора распределяет задачи между воркерами равномерно(при условии что они все подключились к моменту раздачи). Это называется "балансировкой нагрузки"(load
balancing). Это мы опять же рассмотрим позже.

* PULL сокет слива собирает результаты от воркеров равномерно это называется "справедливой очередью" (fairqueuing) (см. рисунок 6).

Конвеерному паттерну(pipeline pattern) так же свойственен синдром "тормоза"(slow joiner), что приводит к обвинению в том что PUSH сокет не правильно использует балансировщик нагрузки. Если вы используете пару PUSH/PULL и один из вашир воркеров получает больше задач чем остальные, это связано с тем что PULL сокет вашего воркера быстрее подключается чем остальные, и хапает слишком много сообщений, пока другие не подключились. Если вы ищите способы правильной балансировки то вам необходимо прочитать на "Продвинутые паттерны запрос-ответ"(Advanced
Request-Reply Pattern) 

### ПРОГРАММИРОВАНИЕ С ЗЕРОЙ. (Programming with ØMQ)

Рассмотрев несколько примеров вы скорее всего уже рветесь внедрять Зеру в свои проекты. Не спешите, сделайте глубокий вдох и задумайтесь над теми советами которые сэкономят вам время и нервы.

* Шаг за шагом полностью изучите Зеру. Это не большая api но она дает уйму возможностей.
* Пишите чистый код. Код с душком несет в себе кучу проблем и усложняет жизнь как вам так и тем кто будет работать после вас. Вы можете превыкнуть к несуразным названиям переменных, но люди кто заглянет в ваш код вздернутся от такого. Используйте именование отражающее реальность. Не надо думать что вы слишком круты чтобы объяснять посредством переменных что происходит в коде. Пишите хороший код и всем будет легче.
* Пишите тесты. Это поможет вам разобраться с магией Зеры и понять что ошибка кроется именно в этих вот пяти строках. Особенно это полезно на первых порах освоения Зеры.
* Если у вас что то работает не так как вы ожидаете, разбейте ваш код на состовные части и протестируйте каржый по отдельности.
* Используйте абстракции(Классы, методы, без разницы). Не забывайте что при копипасте кода вы копируете и ошибки тоже.

### ПОЛУЧАЕМ КОНТЕКСТ ПРАВИЛЬНО (Getting the Context Right)

Первым шагом при работе с Зерой всегда будет создание контекста, и использование его при создании сокетов. В Си это вызов метода zmq_ctx_new(). Можно использовать только один экземпляр контекста на процесс. Говоря техническия языком, контекст это контейнер для сокетов текущего процесса, и выполняет транспортную функцию для сокетов inproc, которые являются самыми быстрыми для передачи данных между процессами. Если процесс имеет два контекста, то они являются разными экземплярами Зеры. Импользуйте несколько экземпляров если вам действительно это необходимо. Однако если нужды в этом не то запомните:

Создавайте только один экземпляр вначале выполнения вашего кода функцией zmq_ctx_new() и не забывайте его удалять по окончанию функцией zmq_ctx_destroy(). Если вы форкаете свои процессы, то каждый из процессов потомков должен иметь своий отдельный контекст. Если вы вызывает zmq_ctx_new() до форка, то можно не беспокоиться, каждый из потомков получит свой собственный контекст. В основном все интересные процессы протекают в процессах потомках, а родительский процесс просто ими управляет.

### ДЕЛАЕМ ЧИСТЫЙ ВЫХОД.

У классных программистов есть девиз - хорошие киллеры всегда подчищают за собой. Если вы использует языки подобные Python, то все почиститься автоматически. Но когда вы используете СИ, необходимо внимательно относиться к уничтожению объектов когда они уже не нужны, иначе вы получите утечку памяти, нестабильное приложение и минус в карму.

Утечка памяти одно дело, другое дело в том что Зера очень чувствительна к тому как вы завершаете свою программу. Если вы оставите открытыми сокеты, то функция zmq_ctx_destroy() будет висеть вечно. Даже если вы позакрываете сокеты, но имеются ожидающие подключения или отправки, то zmq_ctx_destroy() будет ждать вечно, если вы не установить сокетам LINGER в ноль перед их закрытием.

Объекты за которыми нам нужно следить это сообщения, сокеты и контексты. К счастью это довольно легко делается, особенно в простых программах.

* Используйте zmq_send() и  zmq_recv() когда есть возможность, это избавит от непосредственной работы с объектами zmq_msg_t.
* Если вы пользуететсь  zmq_msg_recv(), то как только вы получили сообщение вызывайте zmq_msg_close().
* Если у вас в обороте целая пачка сокетов, которые постоянно приходистся открывать и закрывать, то это звоночек, что вам необходимо пересмотреть архитектуру своего приложения. В большинстве случает сокеты не закрываются до момента закрытия приложения.
* При завершении программы узакройте сокеты и вызовите zmq_ctx_destroy(). В таком случае контекст закроется.

Это все имеет значение если вы программируете на языке подобному СИ. На языках с автосборщикому мусора объекты подчистятся автоматически как только вы закроете программу. если вы используете исключения и операторные скобки, не забывайте подчищать за собой к примеру в блоке "final".

А вот если ваше приложение многопоточное то тут все становится куда сложнее. В следующей главе мы подробно поговорим про мультипоточность, но поскольку многие из вас пытаются бегать до того как научились ходить, то снизу мы на скорую руку накидаем коротенькое руководство о том как завершать многопоточные приложения.

Ну во-первых не используйте один и тот же сокет из разных потоков. Пожалуйста не спорьте об этом, а просто не делайте так и все. После этого нужно отулючить все сокеты имеющие запросы. Верным действием будет установить ожидание(LINGER) равным 1 секунде, после чего закрыть сокет.

Ну и наконец уничтожте контекст. Это приведет к тому что все отправки, получения или накопители дочерних процессов вывалятся с исключениями. Отловите их, установите задержку, и позакрывайте сокеты этих потоков, после чего можно завершить потоки. Не уничтожайте контексты дважды. И не забывайте что zmq_ctx_destroy вызыванная в родительком потоке будет ждать вечно пока не закроются все подключенные потоки.

Вуаля! Это бесчеловечно, заставлять каждого программиста изобретать свой велосипед по завершению программ, но используя языки программирования с авточисткой, такие танцы с бубном становятся не нужны.

### ЗАЧЕМ НАМ ВООБЩЕ НУЖНА ЗЕРА (Why We Needed ØMQ)

Теперь когда мы видели зеру в действии, давайте разберемся зачем она нужна.

На текущий момент множество приложений завязаны на сетевой взаимодействие, будь то внутренняя сеть или интернет. Много разработчиков бьются над проблемой обмена сообщениями. Кто-то использует готовые продукты очередей, но чаще всего пишутся свои велосипеды поверх протоколов TCP и UDP. Это довольно простые протоколы, но пересылка нескольких байт из точки А а точку Б может существенно отличаться и теряется надежность и гибкость.

Давайте рассмотрим типичную проблему с которой мы сталкиваемся при работе через чистый TCP. Любой модуль реализующий работу с сообщениями должен реализовывать большинсво из нижеперечисленного.


1. Как бы обрабатываем ввод-вывод? Мы обрабатываем и блокируем все это в блоке кода приложения или передаем это в отдельный слой на обработку? Это вопрос архитектуры. Блокирование ввода/вывода приводит к жесткой не масштабируемой архитектуре. Однако решение с отдельным слоем обработки очень тяжело реализовать  кореектно.
2. Сможем ли мы обрабатывать динамические сообщения и тп,то что не выходит за рамки шаблонных. Можем ли мы разделить клиенты и серверы, и ожидать что серверы никогда не исчезнут? А что если нам понадобится соединить сервер с сервером? Можем ли мы переподключаться через каждые несколько секунд?
3. Каким образом нам преобразовывать сообщение для передачи через сеть? Как нам поделить передаваемые данные таким образом, чтобы было легко читать и записывать не опасаясь за переполнение буфера, чтобы это было эффективно для маленьких данных, но адекватным для больших видюшек танцующих котиков в шляпах?
4. Как нам обрабатывать сообщения которые требуют немедленной отправки? В частности когда мы ждем, что сдохший компонент снова оживет? Должны ли мы отменить сообщение, положить его в базу данных или же в очередь на оперативной памяти?
5. Где нам хранить очередь сообщений? Что делать если один из компонентов читающих из очереди очень медленный и забивает своим чтением всю нашу очередь? Как мы будем от этого защищаться?
6. Что нам делать с потерянными сообщениями? Будем ли мы ждать обновления данных, запрашивать переотправки данных или же мы реализуем отдельный слой который будет отвечать за гарантированную доставку сообщения? А что если этот слой и развалится?
7. Что будет если нам понадобится использовать разные транспортные протоколы? Скажем широковещательную а не одноадресный TCP? Или к примеру IPv6? Нужно ли переписывать приложение или достаточно будет изменить абстрактный слой?
8. Как нам маршрутизировать сообщения? Можем ли мы отправить одно сообщение множеству подключений? Можем ли мы ответить первоначальному отправителю сообщения?
9. Как нам обмениваться сообщениями между приложеними реализованными на разных языках программирования? Можем ли мы переписать протокол отправки или просто пересобрать библиотеку? Если первое, то как при этом гарантировать стабильность стека сообщений? Если второе, то как гарантировать совместимость?
10. Как представлять сообщение которое может быть прочитано в разных архитектурах? Можем ли мы использовать строгую типизацию?
11. Как нам обрабатывать сбои в сети? Будем ли мы ждать или повторять действие, тихонечко игнорировать или отменять операцию вообще?

Возьмем типовай оупенсорсный проект такой как Hadoop Zookeeper(http://hadoop.apache.org/zookeeper/) и почитаем код на СИ в файле src/c/src/zookeeper.c(http://github.com/apache/zookeeper/blob/trunk/src/c/src/zookeeper.c). Когда я читал этот код в Январе 2013, было примерно 4200 строк загадочного незадокументированного кода, который реализовывал общение клиента с сервером. Я увидел плюс в том что он использует pool вместо select'a. Однако он должен использовать общий слой для работы и строго документированный протокол обмена сообщеними. Совершенно недопустимо кажды раз изобретать собственный велосипед снова и снова.

Но как сделать общий слой обмена сообщениями? Почему когда разработчикам требуется обмен сообщенями они реализовывают это поверх чистого TCP и решают все перечисленные проблемы снова и снова?

Оказывается реализация многоразовых систем обмена сообщениями не так то просто реализовать, поэтому многие FOSS(открытое свободное по) проекты пытавшиеся это сделать, проваливались, а коммерческие поекты были дико дорогими,сложными, хрупкими и не гибкими. В 2006 году iMatix разработала AMQP, и раздал его разработчикам FOSS, возможно первый в своем роде рецепт для создания универсального обмена сообщениями. AMQP работает лучше многих других подобных конструкций, но остается достаточно сложным, дорогим и хрупким.Требуются недели на то чтобы разобраться и месяцы чтобы построить стабильную архитектуру, которая не падает при увеличении функционала. 